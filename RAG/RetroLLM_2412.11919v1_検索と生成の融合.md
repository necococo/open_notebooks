# RetroLLM: 検索と生成の統合
[paper](https://arxiv.org/html/2412.11919v1)<br>
[github repo](https://github.com/sunnynexus/RetroLLM)

---

## 1. はじめに

**RetroLLM**は、大規模言語モデル（LLM）を用いた検索拡張生成（Retrieval-Augmented Generation, RAG）の新しいアプローチです。

### 大規模言語モデルの課題と解決策
- 課題: 大規模言語モデル（LLM）は外部情報と同期できず、最新の情報を反映しにくい → 幻覚（誤情報）発生
- 解決策: **RAG（Retrieval-Augmented Generation）** → 外部の知識を検索して回答を生成

### RAGの問題点
- 検索と生成が独立している → 重要な情報を拾いきれない、不要情報を含み処理が遅くなる

### RetroLLMの基本構造
- 下図にあるようにLLM が知識ソースから事実の証拠(Fine-grainded Evidences)を生成し、自己回帰生成プロセス内(Auto-regressive Generate)で最終的な回答を生成できるようにする。従来のRAG手法で発生していた情報の見落としや不要情報の混入といった問題を解決します。

![Figure 1-c](https://imgur.com/Em2kEZR.png)

*Figure 1-c*

---

### Figure 3の説明
![Figure 3-a](https://imgur.com/AOan6A9.png)
*Figure 3*

### **🔹 Figure 3-a: RetroLLM の具体的な処理フロー（ノーベル賞の例）**

#### **質問**
「最初のノーベル物理学賞を受賞したのは誰か？ またそれは何年か？」

RetroLLM は **FM-Index** を活用し、検索と証拠生成を統合しながら回答を導きます。

#### **【1回目の処理】**

1.  **クルー（Clue）の生成:** 質問の中から、検索キーワードを抽出する。（例: ノーベル賞、物理学）
2.  **関連文書の検索:** クルーを用いて、関連性の高い文書をコーパスから絞り込む。（例: 文書B「ウィルヘルム・レントゲンの受賞」）
3.  **Evidence の生成:** 関連文書から、質問に対する回答の根拠となる情報を抽出する。（例: 「最初のノーベル物理学賞は物理学者ヴィルヘルム・レントゲンに授与された」）

#### **【2回目以降の処理】**

1.  **追加のクルー生成:** 1回目の処理で不足している情報を取得するために、新しい検索キーワードを生成する。（例: ヴィルヘルム・レントゲン、1901年）
2.  **追加の文書検索:** 新しいクルーを用いて、関連性の高い文書をコーパスから絞り込む。
3.  **追加の証拠生成:** 新しい関連文書から、質問に対する回答の根拠となる情報を抽出する。

**ポイント:**

*   RetroLLM は、質問に対して一度の検索で完璧な回答を得るのではなく、（自己回帰的に）複数のステップを繰り返すことで、徐々に情報を集めて回答を生成します。
*   FM-Index と Forward-Looking Constraints を活用することで、効率的かつ正確な情報取得を実現しています。

---

## 従来手法との比較

![Figure 1](https://imgur.com/Xybuqb8.png)

Figure 1 (a) 伝統的なRAG、(b) ジェネレーティブリトリーバーを使うRAG、(c) RetroLLM

*   **(a) 伝統的RAG:** 検索と生成を独立に行うため、情報参照が固定的になりがち。
*   **(b) Generative Retrieval-based RAG:** Retrieverを生成モデル化するが、文書IDベースのため細粒度の証拠取得には限界がある。
*   **(c) RetroLLM:** 検索と生成を**自己回帰的**に統合し、必要に応じて細かい文章断片を取得できる。

**RetroLLM は、検索と生成を密接に結びつけ、より柔軟かつ正確な情報取得を実現します。**

---

## 3. 実験結果と性能

### 実験結果
- 精度向上: 複雑な質問（特にマルチホップQA）で精度が向上
- トークン数削減: 従来の RAG と比較して平均 2.1 倍効率的（不要な情報を排除）

**RetroLLM は、従来の RAG と比較してトークン数を削減しつつ、精度を向上させました。** 例えば、オープンドメイン QA タスクでは、Natural Questions データセットで 61.6% の精度、TriviaQA で 74.3% の精度を実現しました。

## 4. 今後の課題と展望

### 今後の課題
- 計算コストの最適化: 前方予測で精度を向上させつつ処理速度を維持
- 検索精度の改善: 重要な手がかりをより正確に選択

**RetroLLM は、計算コストの最適化と検索精度の改善という課題を抱えています。** 今後は、より効率的なアルゴリズムの開発や、大規模なコーパスでの検証が求められます。

---

## 5. まとめ

まとめ: RetroLLM は検索と生成を統合し、より高精度・効率的な情報取得を実現する技術として注目されています。

