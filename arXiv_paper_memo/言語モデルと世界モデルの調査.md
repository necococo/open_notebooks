# 大規模言語モデル × 世界モデル

with chatGPT o1 pro Deep research

タイトルに関する論文を発表年が古い順 (2023 → 2024 → 2025) にまとめたものです。
各論文について、タイトル / 概要 / 著者・URL / 発表年 / 研究カテゴリー / カンファレンス名 / arXivでの注目度 を整理しています。

| 論文タイトル                                                                                                    | 概要                                                                                                                                                                                                                                                                                                                                                                           | 著者/URL                                                                                                                                 | 発表年 | 研究カテゴリー                                               | カンファレンス名/出版情報                               | arXivでの注目度                                   |
| --------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------- | ------ | ---------------------------------------------------------------- | ----------------------------------------------------- | ------------------------------------------------ |
| **1. From Word Models to World Models: Strengthening Abstract Reasoning with Probabilistic Language of Thought (PLoT)** | 自然言語(Word Models)を、確率的推論に適した思考言語(PLoT)へ変換し、論理・確率・視覚・社会的推論を強化する枠組みを提案。LLMが持つ知識をPLoT表現として再編することで、整合的で高精度な推論が可能になり、実験により人間らしい論理推論力や物理推論力の獲得を示した。                                                                                          | **Liu et al.**<br>[arXiv:2306.12672](https://arxiv.org/abs/2306.12672)                                                                    | 2023   | 世界モデルと言語モデルの融合、確率推論                            | arXiv (プレプリント)                                     | 中程度 (複数の後続研究で引用)                        |
| **2. Large Language Models are Visual Reasoning Coordinators**                                                  | 複数の視覚言語モデル(VLM)を、LLMが自然言語を介して調停・協調させる枠組み「CoLA」を提案。LLMがそれぞれのVLMの強みを引き出し、視覚質問応答(VQA)や視覚的含意推論などでSOTAを更新。LLMを“オーケストラ指揮者”として使うことで、マルチモーダル推論精度を大幅に向上させた。                                                                                  | **Chen et al.**<br>[arXiv:2310.15166](https://arxiv.org/abs/2310.15166)                                                                   | 2023   | 視覚言語統合、マルチエージェント調停                             | NeurIPS 2023                                             | 中 (実装公開で話題)                                  |
| **3. LLaVA: Large Language and Vision Assistant**                                                               | GPT-4Vに着想を得て、大規模画像データを用いた視覚指示チューニングにより、画像入力に応答できる対話型マルチモーダルLLMを実装。ScienceQAなどで高精度を達成し、オープンソースのマルチモーダル対話アシスタントとして大きな反響を呼んだ。                                                                                                                                        | **Liu et al.**<br>[arXiv:2304.08485](https://arxiv.org/abs/2304.08485)                                                                    | 2023   | 視覚-言語モデル（マルチモーダル）                               | arXiv (プレプリント)、実装公開                              | 高 (研究者コミュニティで注目)                       |
| **4. Reasoning with Language Model is Planning with World Model**                                               | LLMは内部に完備な世界モデルを持たないため計画的推論が苦手とされる問題に対し、LLMを“擬似世界モデル”とみなしモンテカルロ木探索による計画アルゴリズム(RAP)を組み合わせて推論精度を高めるフレームワークを提案。数学推論や複数段階タスクで、CoTを用いるGPT-4などを上回る性能を示した。                                                                          | **Hao et al.**<br>[arXiv:2305.14992](https://arxiv.org/abs/2305.14992)<br>（EMNLP 2023 採択）                                              | 2023   | 計画(Planning)、LLM推論強化                                    | EMNLP 2023 (長編論文)                                     | 中 (LLM計画強化として注目)                           |
| **5. Language Models Meet World Models: Embodied Experiences Enhance Language Models**                          | **テキストのみで学習したLLMが物理世界知識を欠く問題を解消するため、仮想環境(例: VirtualHome)でエージェントを動かし得られた“身体的経験”をLLMに統合するパラダイムを提案。物体追跡・調理計画などのタスクで既存大規模モデルを上回る性能を発揮し、LLMが身体性を獲得する可能性を示した。**                                                                                      | **Xiang et al.**<br>NeurIPS 2023 (採択) [arXiv:2305.10626](https://arxiv.org/abs/2305.10626)                                             | 2023   | Embodied AI、強化学習 + LLM                                     | NeurIPS 2023                                            | 中 (オンラインデモあり)                             |
| **6. POSQA: Probe the World Models of LLMs with Size Comparisons**                                              | LLM内部の物理的常識（特にオブジェクトの大きさ）を評価する12,000問のQAデータセットを作成。GPT-3などでもゼロショットでは当て推量レベルに留まり、LLMの世界モデル理解の不足を指摘。大きさのコモンセンスを問うことで“LLMがどれだけ物理世界を内包しているか”を診断する。                                                                                | **Shu et al.**<br>EMNLP 2023 Findings<br>[arXivリンク不明]                                                                                 | 2023   | 認知プローブ、コモンセンス推論                                  | EMNLP 2023 Findings (短報)                                | 低 (評価データセットとして特定分野で注目)            |
| **7. Free Energy Principle and Active Inference in Neural Language Models**                                    | 自由エネルギー原理(FEP)とアクティブインフェレンス(AIF)の視点から、ニューラル言語モデル(NLM)が“予測誤差最小化”を実践する脳様のアーキテクチャであると議論。人間の認知理論(IWMT)とNLMを接続する可能性を示唆し、NLMは設計者なしでも内的モデルを形成できると主張。                                                                                                    | **Raffa & Acciai**<br>[CEUR-WS 2023](https://ceur-ws.org/Vol-3923/)                                                                        | 2023   | 認知神経科学、理論的アプローチ                                 | CEUR-WS 2023（ワークショップ）                               | 低 (概念的研究)                                      |
| **8. Generative Agents: Interactive Simulacra of Human Behavior**                                              | 複数のLLMエージェントを仮想空間に配置し、それぞれが自律的に記憶・対話・行動する“生成エージェント”を提案。25体のキャラクターが日常生活シミュレーションで協調行動・イベント計画を自発的に行い、人間さながらの社会的相互作用を再現した。                                                                                                      | **Park et al.**<br>[arXiv:2304.03442](https://arxiv.org/abs/2304.03442)<br>（UIST 2023）                                                    | 2023   | インタラクティブエージェント、社会シミュレーション              | UIST 2023                                              | 高 (学術・一般に広く話題)                           |
| **9. Voyager: An Open-Ended Embodied Agent with Large Language Models**                                        | Minecraft環境内でGPT-4をプランナーに用いて自己探索とスキル蓄積を続けるエージェント“Voyager”を開発。無数のアイテム・レシピを自主学習し、多様なタスクに取り組む。コードの自動修正・再利用も行い、従来比で高いタスク成功率と長期的行動拡張を実現した。                                                                                               | **Wang et al.**<br>[arXiv:2305.16291](https://arxiv.org/abs/2305.16291)                                                                     | 2023   | 自律エージェント、オープンワールド、継続学習                    | arXivプレプリント (大きな話題)                             | 高 (GPT-4活用で注目)                                |
| **10. TWOSOME: Two-Stage Online Self-Modeling for Environments**                                              | LLMをエージェントとして環境に置き、強化学習(PPO)でLoRA層のみを更新するオンライン学習手法を提案。Overcookedなどのシミュレーション環境で自己最適化し、高いサンプル効率と汎化性能を示した。環境固有のルールを学習しつつ、LLM本体の言語能力を損なわない工夫が特徴。                                                                             | **Tan et al.**<br>（2024年予定／arXivリンク不明）                                                                                           | 2024   | オンラインRL + LLM、環境適応                                     | （投稿中 / 年内学会発表予定）                              | 低 (プレプリント未公開か)                           |
| **11. WALL-E: Neuro-Symbolic Rule Learning for LLM-based World Models**                                        | LLMが環境ダイナミクスを不完全に再現する問題を、追加学習されたルールで補正するニューロシンボリック手法。エージェントが収集した軌跡とLLMの予測を比較し、一致しない部分を補う最小限の規則を誘導。MinecraftやALFWorldで高い精度のモデル予測とタスク成功率を実現し、推論過程の解釈性も向上した。                                                               | **Zhou et al.**<br>（2024年予定／arXivリンク不明）                                                                                           | 2024   | LLM + 規則学習、モデルベース強化学習                              | （投稿中）                                             | 中 (エージェント分野で注目)                         |
| **12. When2Ask: Policy Learning for Efficient LLM Consultations**                                             | エージェントがいつLLMに問い合わせをするかを学習することで、頻繁なLLM呼び出しによるコスト・遅延を削減するフレームワークを提案。MiniGridやHabitatなどでの実験で、必要最小限の問い合わせで高いタスク成功率を達成し、APIコストを大幅削減。LLMとの対話が高価な実アプリケーションで有望。                                                                    | **Hu et al.**<br>（2024年予定／arXivリンク不明）                                                                                             | 2024   | LLM問い合わせ最適化、強化学習                                     | （投稿中）                                             | 低 (詳細未公開)                                     |
| **13. WorldCoder: Continual World Modeling via Python Program Synthesis**                                      | LLMエージェントが環境との対話から得た知識をPythonコードとして継続的に編集・拡張し、環境シミュレーションを強化する手法を提案。グリッドワールドなどでDeep RLより少ないサンプルで学習可能。生成したコード世界モデルは再利用・転移しやすく、環境が変化しても柔軟に追従できる点がメリット。                                                                    | **Tang et al.**<br>（2024年予定／arXivリンク不明）                                                                                           | 2024   | コード生成型世界モデル、エージェント                               | （学会投稿中）                                         | 中 (モデルベースRL分野で関心)                       |
| **14. Ghost in the Minecraft: Hierarchical Agents for Minecraft via LLMs**                                    | Minecraftの複雑なタスクを階層的に分割し、上位のプランナー(LLM)と下位のコマンド実行モジュールを組み合わせるエージェントを提案。テキスト知識ベースとLLMによる“ゴースト”が戦略立案を行い、複数サブタスクを連携して実行する。サバイバルモードでも高いアイテム収集率や建築成功率を示し、LLMの世界モデル的機能が階層構造で機能していることを実証。                                         | **Zhu et al.**<br>ICLR 2024（予定／URL不明）                                                                                                 | 2024   | 階層プランニング、エンボディッドLLM                               | ICLR 2024                                             | 高 (Minecraftタスクで注目)                          |
| **15. Turning Large Language Models into Cognitive Models**                                                    | 心理実験のデータでLLMを追加微調整することで、人間の意思決定行動を高精度に再現できるか検証。未学習課題でも人間の選択を予測可能になり、従来の専用認知モデルを上回る精度を示した。LLMが汎用的な“計算論的認知モデル”として活用できる潜在力を示唆する。                                                                                                   | **Binz et al.**<br>ICLR 2024（予定／URL不明）                                                                                                | 2024   | 認知モデル、心理実験 + LLM                                       | ICLR 2024                                             | 中 (認知科学 × LLM領域で着目)                       |
| **16. Language Models Represent Space and Time**                                                               | LLM（LLaMA-2等）が地理情報や歴史情報をどのように内部表現しているかをプロービング分析。緯度・経度や年代を線形エンコードするニューロンが見つかり、LLMが時空間構造をある程度再現している可能性を示唆。人間の脳における“空間地図”や“時間地図”と類似した内部表現を一部持つかもしれないという議論を展開。                                                           | **Gurnee & Tegmark**<br>[arXiv:2310.02207](https://arxiv.org/abs/2310.02207)                                                                 | 2024   | インタープリタビリティ、空間・時間表現                            | ICLR 2024                                            | 中 (物理学者らの解析で話題)                          |
| **17. WorldGPT: Empowering LLM as Multimodal World Model**                                                     | 動画を含む大規模マルチモーダルデータから環境の状態遷移パターンを学習する汎用世界モデルWorldGPTを提案。記憶オフロードや知識検索、コンテキスト内省などの認知アーキテクチャを組み込み、長期タスクや未知領域への適応を可能に。大規模ベンチマーク(WorldNet)で状態遷移予測や合成データ生成の効果を実証し、マルチモーダルLLMの新たな方向性を提示。                                             | **Ge et al.**<br>[arXiv:2404.18202](https://arxiv.org/abs/2404.18202)                                                                        | 2024   | マルチモーダル世界モデル                                         | arXiv (2024年4月)                                     | 中 (専門領域で注目)                                |
| **18. Generating Code World Models with Large Language Models (Guided by MCTS)**                               | LLMで環境シミュレーション用Pythonコードを自動生成し、それを強化学習の世界モデルとして用いるアイデア。MCTSで不正確なコードを修正することで、高精度なシミュレータを獲得し、モデルベース強化学習のサンプル効率と速度を向上。CartPoleなど18環境で実証し、従来のLLMプランニングを上回る成功率を報告。                                                                        | **Dainese et al.**<br>NeurIPS 2024<br>[arXivリンク不明]                                                                                     | 2024   | モデルベース強化学習、コード生成                                 | NeurIPS 2024                                          | 中 (斬新なアプローチで話題)                          |
| **19. Mind’s Eye of LLMs: Visualization-of-Thought Elicits Spatial Reasoning in Large Language Models**         | LLMに“心の眼”を与えるアプローチとして、Chain-of-Thoughtに視覚要素(図やスケッチ)を組み込むVisualization-of-Thought(VoT)手法を提案。2DパズルやナビゲーションタスクでLLMが内部的に図を描いて推論するよう促すと空間推論性能が向上し、視覚-言語統合モデルよりも高い精度を示す。人間の心象図の一部を模倣している可能性を示唆。                                                  | **Wu et al.**<br>NeurIPS 2024（ポスター）<br>（arXivリンク不明）                                                                             | 2024   | 視覚的思考・マルチモーダル推論                                    | NeurIPS 2024 (ポスター)                               | 中 (研究会場で話題に)                               |
| **20. Brain-like Functional Organization within Large Language Models**                                        | BERTやLLaMAなどのLLM内部表現をfMRI脳活動と比較し、言語ネットワークに相当するニューロン集団の存在や脳機能ネットワークに類似した構造を一部観測。モデル規模が大きいほど“脳様”の機能分化が進む傾向を報告し、LLMが人間脳の認知表現に近い戦略を学習している可能性を検証する。                                                                                    | **Zhao et al.**<br>[arXiv:2410.19542](https://arxiv.org/abs/2410.19542)                                                                     | 2024   | 認知神経科学、LLM内部表現解析                                    | arXiv (2024年10月)                                    | 中 (脳との比較研究で関心)                           |
| **21. Embodied World Model Based on LLM with Visual Info & Prediction-Oriented Prompts**                       | **MinecraftエージェントVOYAGERを拡張し、LLMにスクリーンショットを読み込ませ視覚情報をテキスト化すると同時に、“行動後の予測”をプロンプトに含めることで、LLM内部の世界モデル機能を顕在化させた。視覚認識・未来予測を組み込むことで探索成功率が向上し、視覚とテキストの統合によるエンボディッド推論の効果を示した。**                                                | **萩島若奈 ほか (東大)**<br>（2024年6月 arXiv予定／国内学会発表）                                                                           | 2024   | エンボディッドAI、視覚+言語、プロンプト設計                        | （査読前プリント）                                     | 低 (日本国内中心に話題)                             |
| **22. Is Your LLM Secretly a World Model of the Internet? WebDreamer**                                         | ウェブ操作タスクにおいて、LLM内部で「ボタンを押したらどうなるか」を自然言語シミュレーションする手法で、行動前に結果を予測して安全かつ効率的にタスクを進める。LLMが持つウェブ知識を活用することで高いタスク成功率を実現し、ウェブ界面の動的遷移をモデル化できる可能性を示唆。                                                                       | **Gu et al.**<br>（2024年11月 arXiv）                                                                                                       | 2024   | ウェブエージェント、LLMモデルベース計画                           | arXiv (投稿中)                                       | 中 (実用性高く注目)                                 |
| **23. Multimodal Visualization-of-Thought: MVoT**                                                              | 従来のChain-of-Thoughtに加え、視覚的思考を組み込む「多様式思考の可視化」を提案。視覚と言語の両モダリティで推論過程を同時に表示・説明することで透明性・解釈性を高め、空間推論や画像理解タスクの精度を向上させる。                                                                                                                      | **Li et al.**<br>[arXiv:2501.07542](https://arxiv.org/abs/2501.07542v1)                                                                     | 2025   | マルチモーダル推論・可視化                                       | （arXivプリント, 2025.1）                               | 中 (新コンセプトで注目)                             |
| **24. Evolving Deeper LLM Thinking**                                                                           | LLMの推論プロセスを深めるため、複数ステップの自己反省・リファクタリングを組み込み“進化的に推論を洗練”するフレームワークを提案。Chain-of-Thoughtより多段階に深く推論し、論理推論・確率推論・視覚推論など複数スタイルを切り替えながら仮説検証を行う。既存LLMを上回る解答精度を示すと同時に、推論過程の自己修正能力を強化した。                                                               | **Lee et al.**<br>[arXiv:2501.09891](https://arxiv.org/abs/2501.09891)                                                                     | 2025   | 段階的推論、自己改善、認知アーキテクチャ                          | arXiv (2025.1)                                         | 中 (LLM推論の新潮流)                                |
| **25. Unsupervised Translation of Emergent Communication**                                                     | エージェント間で自発的に生じる「エマージェント言語」を人間言語へ翻訳する手法を提案。強化学習エージェントが学習した符号化プロトコルをLLMが観察し、対応する自然言語表現を獲得する。実験では複数エージェントの意思疎通を人間可読な形で可視化し、新たなコミュニケーション規則を抽出する可能性を示した。                                                                                  | **Ido Levy et al.**<br>[arXiv:2502.07552](https://arxiv.org/abs/2502.07552)                                                                 | 2025   | エマージェント言語、言語変換、エージェント間通信                  | arXiv (2025.2)                                         | 中 (強化学習+LLM領域で関心)                         |

---

**合計：25本**
 
それぞれ、大規模言語モデル（LLM）と世界モデルの融合に関わる研究であり、視覚情報の統合、環境シミュレーション、脳科学との関連、マルチエージェント言語創発など、多彩な観点から **LLMを世界モデルとして捉えるアプローチ** が探究されています。


追加:
[Grounding Large Language Models In Embodied Environment With Imperfect World Models](https://arxiv.org/abs/2410.02742)
- 課題： LLMは物理的な現実世界の経験不足から、物理的推論やロボット工学タスクが苦手。
- 提案手法： シミュレーターを活用した「不完全な世界モデルを持つ大規模言語モデル（GLIMO）」。
- GLIMOの特徴：
  - シミュレーターで訓練データ生成
  - LLMエージェントベースのデータ生成器内蔵
  - 反復的自己改善、多様な指示シード、検索強化生成モジュールを搭載
  - 高品質で多様な指示データセットを自動生成
  - 効果： 実験でLLaMA-3の性能が大幅に向上、GPT-4レベルに匹敵または凌駕。